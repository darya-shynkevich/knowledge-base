# 1. Use a better algorithm.

! The selection sort algorithm above is faster than the bubble sort for random data, but the bubble sort is much faster for sorted data. ***The relationship between inputs and algorithmic performance can be subtle***. Famously, if you choose an unfortunate “pivot” when implementing [quicksort](https://en.wikipedia.org/wiki/Quicksort), you’ll find that it is very non-quick (e.g. you can make it as slow on already-sorted data as the selection sort above).

=> “use a better algorithm” requires understanding the wider context of your system and the nature of the algorithm you’re thinking of using.

# 2. Use a better data-structure

Just as with “use a better algorithm”, “use a better data-structure” requires careful thought and measurement.

! There is an important tactical variant on “better data-structures” that is perhaps best thought of as ***“put your structs/classes on a diet”***.
	1. reducing objects size
	2. reducing “pointer chasing” (typically by folding multiple structs/classes into one)
	3. encouraging memory locality <= it’s difficult to measure the indirect impact

! **Inefficient Data Formats** — XML results in larger payload sizes compared to lightweight formats like JSON, then requires more bandwidth and time for transmission.

# 3. Use a lower-level system

1. check that you’ve got compiler optimisations turned on, 
2. use faster libraries or databases

Sometimes rewriting in a lower-level programming language really is the right thing to do, but it is rarely a quick job, and it inevitably ***introduces a period of instability while bugs are shaken out of the new version.***

# 4. Accept a less precise solution

[local search](https://en.wikipedia.org/wiki/Local_search_(optimization)). => we define a metric (in our running example, how fast our benchmark suite runs) that allows us to compare two solutions (in our case, faster is better) and discard the worst. 
	1. [fast inverse square root](https://en.wikipedia.org/wiki/Fast_inverse_square_root) approximates multiplicative inverse
	2. [Bloom filter](https://en.wikipedia.org/wiki/Bloom_filter) can give false positives: accepting that possibility allows it to be exceptionally frugal with memory
	3. JPEG image compression deliberately throws away some of an image’s fine details in order to make the image more compressible

***Unless you are convinced you can tolerate incorrectness, you’re best off assuming that you can’t.***

# 5. Use cache

Without caching, the server performs redundant computations for similar requests, leading to slower response times. It regenerates data for each request, straining resources like CPU and memory.

# 6. Network

 The physical distance between client and server introduces latency due to the finite speed of light, causing delays in data transmission. **Network congestion** from routers and switches can lead to packet delays or loss, exacerbating latency. **Limited network bandwidth** can restrict data transmission, resulting in queuing delays, especially during peak usage periods. Network protocols add processing overhead, contributing to latency. In wireless networks, factors like signal interference and environmental conditions can further increase latency compared to wired connections.

! **Larger payloads** also increase network latency, especially over networks with limited bandwidth or high latency, causing delays in delivering API responses

# 7. RPC

**Series call** — Sequentially calling multiple remote APIs one after the other to gather necessary data. This leads to poor performance as the total time taken is the sum of the taken by each call.

**Parallel call** — Simultaneously calling multiple remote APIs to fetch data concurrently, significantly reducing the overall time taken.

# 8. [Transactions](1.%20Software%20Engineering/3.%20Database/OTLP/SQL/3.%20Transactions/_Base.md)

Problems with long-running transactions:
- **Deadlock** — Transactions waiting on each other can cause a system halt.
- **Long Rollback Times** — Long transactions can take time to roll back, affecting performance.
- **Connection Pool Exhaustion in High Concurrency** — High concurrency can lead to the exhaustion of database connections.
- **Lock Waits** — Transactions waiting for locks can delay operations.
- **Timeouts** — Long transactions may exceed timeout limits, causing failures.
- **Database Master-Slave Delay** — Replication delays between master and slave databases can lead to stale reads.

=>
1. Execute non-transactional SELECT queries outside the transaction boundary to avoid unnecessary rollback overhead
2. Minimize remote calls within transactions to prevent latency. If unavoidable, ensure efficiency and implement timeouts
3. Process data in smaller batches to reduce resource contention
4. Execute operations not requiring transactional consistency outside transactions, like read-only tasks
5. Consider asynchronous processing for independent tasks

# 9. **Lock Granularity**

In business scenarios, locking mechanisms prevent multiple threads from concurrently modifying shared data, avoiding data anomalies. However, improper locking can lead to coarse lock granularity, impacting performance.

1. **Method-Level Locking** Locking an entire method can degrade performance if only part of the method requires locking.
2. 

=>
1. to improve performance, lock only the critical section of the code

# References:

1. ~~[Four Kinds of Optimisation](https://tratt.net/laurie/blog/2023/four_kinds_of_optimisation.html)~~
2. ~~[Mastering API Performance Optimization Part 1](https://jinlow.medium.com/mastering-api-performance-optimization-1-4f82ac5cf792)~~
3. [Mastering API Performance Optimization Part 2](https://jinlow.medium.com/mastering-api-performance-optimization-2-2b078f893272)