1. messages are persistent on the disk, it provides an ability to keep the history of events or replay the full sequence
2. usually are easier to scale
3. the main representatives of the log-based group are Apache Kafka, Apache Pulsar and Amazon Kinesis.

As it follows from the name, the main difference to [1. Queue-based](1.%20Queue-based.md) of log-based message brokers is the usage of the log as a store for messages. ***Log is persistent storage*** and therefore several consumers can read from it in parallel.

![Pasted image 20231205214546](../../../../../_Attachments/Pasted%20image%2020231205214546.png)

1. Each producer writes to a specific topic
2. Kafka is append-only system
3. Consumers **polling** from a specific topic and partition 
# Partitions = shards

# Queue vs [Pub Sub](Pub%20Sub)

1. Queue: Message published once, consumed once
2. Pub Sub: Message published once, consumed many times
3. Kafka asked: How can we do both? => Consumer Group
# Consumer Group

1. were invented to do parallel processing on partition
2. if there is only one consumer, it will receive messages from all partitions, if another consumer joined the group => they will be rebalanced
![Pasted image 20231205215956](../../../../../_Attachments/Pasted%20image%2020231205215956.png)

3. one partition better be consumed by one consumer and consumer group controls this => you will be able to consume in parallel

Summary:
1. To act like a queue, put all your consumers in one group
2. To act like pub/sub, put each consumer in unique group

# Polling

Each consumer works at its own speed and reads the message from the different position in the log. On one side it makes them independent from each other and more decoupled from the broker. Another advantage is that multiple consumers can work with a single log, so there is no need to create additional entities for that purpose as in the case of queue-based brokers.

But this approach leads to another complexity — consumers’ offsets (or cursors) must be stored somewhere. Having them saved somewhere inside consumers is not a good idea. If a consumer fails or is stale and replaced by another one, the new one should have access to the previous instance cursor, otherwise, it starts reading messages from the beginning which is usually not what we want.

![Pasted image 20231205132650](../../../../../_Attachments/Pasted%20image%2020231205132650.png)

One example of this approach is Apache Kafka — it stores consumers’ offsets in the internal topic called `___consumer_offsets_`. Apache Pulsar does something similar: it saves cursors in the BookKeeper like the other data.


